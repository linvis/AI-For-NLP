{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Review the course online programming code.\n",
    "\n",
    "see lecture-2/online/online.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review the main points of this lesson.\n",
    "\n",
    "1. How to Github and Why do we use Jupyter and Pycharm;\n",
    "Ans: 熟练掌握git和jupyter和pycharm\n",
    "\n",
    "2. What's the Probability Model?\n",
    "Ans:根据已有数据，推断某件事发生的概率\n",
    "\n",
    "\n",
    "3. Can you came up with some sceneraies at which we could use Probability Model?\n",
    "Ans:天气预报，博彩\n",
    "\n",
    "4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?\n",
    "Ans:1. 随着语句复杂度增加，语法解析和匹配爆炸增长，2. 对于无法解析和匹配的语句没有很好的处理能力\n",
    "\n",
    "\n",
    "5. What's the Language Model;\n",
    "Ans:通过对语句切片，根据各片的已有使用概率，分析组合后语句的发生概率 \n",
    "\n",
    "\n",
    "6. Can you came up with some sceneraies at which we could use Language Model?\n",
    "Ans:输入法中或者word中的输入纠正，情感分析\n",
    "\n",
    "7. What's the 1-gram language model;\n",
    "Ans:切片的最小单元为1个单词, $$P = p_1*p_2*p_3...*p_n$$\n",
    "\n",
    "\n",
    "8. What's the disadvantages and advantages of 1-gram language model;\n",
    "Ans:优势：简单，快捷，\n",
    "    劣势：准确率较低\n",
    "\n",
    "9. What't the 2-gram models;\n",
    "Ans:切片的最小单元为1个单词, $$P = p_12*p_23*p_34...*p_{(n-1)(n)}$$\n",
    "\n",
    "10. what's the web crawler, and can you implement a simple crawler?\n",
    "Ans:爬虫：获取网络上公开数据的程序\n",
    "\n",
    "11. There may be some issues to make our crwaler programming difficult, what are these, and how do we solve them?\n",
    "Ans:登陆限制：模拟登陆；\n",
    "    浏览器限制：模拟浏览器；\n",
    "    频率限制：降低频率；\n",
    "    IP地址限制：变换IP地址；\n",
    "\n",
    "12. What't the Regular Expression and how to use?\n",
    "Ans:从字符串中获取特定字符串的表达式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Wikipedia dataset to finish the language model.\n",
    "see lecture-2/homework/wikipedia/wikipedia.py (based on Pycharm)\n",
    "\n",
    "#### 程序概述\n",
    "\n",
    "这里我使用了大概500M左右的维基百科资料，出于缩短程序时间的目的。\n",
    "\n",
    "我的环境是2015款 15寸macbook pro(4核i7)\n",
    "\n",
    "程序里开了5个进程，4个进程用来读取文件，清洗数据，分词，然后通过queue扔给第5个进程。\n",
    "\n",
    "第5个进程里，对分词进行Counter并累加。\n",
    "\n",
    "分词使用的是one gram的形式\n",
    "\n",
    "#### 性能分析\n",
    "\n",
    "500M跑了7分钟的样子\n",
    "\n",
    "主要耗时在jieba分词上，基本1M的数据运行时间在2.6s左右，速度500kb/s左右，符合官方的数据\n",
    "\n",
    "> 我试过jieba.enable_parallel()，很奇怪，开启后分词反而更慢了，为了验证是否是由于我开了5个进程，\n",
    ">\n",
    "> 我关闭所有进程，只保留主进程，进行分词，也是变得更慢了，和官方宣称的完全相反\n",
    "\n",
    "此外，随着Counter的增加(约计算300M数据)，Counter运行时间约线性增加(500M结束前的1M，耗时在1.8s)\n",
    "\n",
    "#### 测试\n",
    "测试了2个case\n",
    "one_gram_prob(\"今天晚上请你吃大餐，我们一起吃日料\")=3.9884478889479566e-54\n",
    "one_gram_prob(\"这是一个关于维基百科的语言模型测试\")=3.7073787613579593e-28\n",
    "\n",
    "概率特别低，推测是两个原因，一是数据量不够，二是Wikipedia的语言比较书面\n",
    "\n",
    "\n",
    "#### questions\n",
    "Step 5: If we need to solve following problems, how can language model help us?\n",
    "\n",
    "Voice Recognization.  \n",
    "我认为可以帮助做语音纠正，输入可能不正确，通过概率尝试纠正输入\n",
    "\n",
    "Sogou pinyin input.  \n",
    "同上，文本输入纠正\n",
    "\n",
    "Auto correction in search engine.  \n",
    "同上，文本输入纠正\n",
    "\n",
    "Abnormal Detection.  \n",
    "没理解这个场景代表的意思\n",
    "\n",
    "Compared to the previous learned parsing and pattern match problems. What's the advantage and disavantage of Probability Based Methods?\n",
    "优势：减少编码，对于新句子新单词有识别的可能\n",
    "劣势：目前来看，对于语句的处理，基本是机器自己的判断(机器根据已有数据进行判断)。匹配模型是人类根据设定语言规则，让机器按照"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
