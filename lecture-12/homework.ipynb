{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.value = None\n",
    "        self.outputs = []\n",
    "        \n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "        \n",
    "        self.gradient = {}\n",
    "        \n",
    "    def forward(self):\n",
    "        raise NotImplemented\n",
    "        \n",
    "    def backward(self):\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        Node.__init__(self)\n",
    "        \n",
    "    def forward(self):\n",
    "        return self.value\n",
    "        \n",
    "    def backward(self):\n",
    "        grad_cost = self.outputs[0].gradient[self]\n",
    "        self.gradient[self] = grad_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Node):\n",
    "    def __init__(self, nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "        \n",
    "    def forward(self):\n",
    "        self.values = sum([n.value for n in self.inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weight, bias):\n",
    "        Node.__init__(self, [nodes, weight, bias])\n",
    "        \n",
    "    def forward(self):\n",
    "        x = self.inputs[0].value\n",
    "        weight = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "        \n",
    "        #weight = weight.reshape(-1, 1)\n",
    "        self.value = np.dot(x, weight) + bias\n",
    "        \n",
    "        return self.value\n",
    "        \n",
    "    def backward(self):\n",
    "        grad_cost = self.outputs[0].gradient[self]\n",
    "        #print(\"linear {}\".format(grad_cost.shape))\n",
    "        \n",
    "        x = self.inputs[0].value\n",
    "        weight = self.inputs[1].value\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #print(weight.shape)\n",
    "        #print(grad_cost.shape)\n",
    "        #grad_cost = grad_cost.reshape(grad_cost.shape[0], -1)\n",
    "        #weight = weight.reshape(weight.shape[0], -1)\n",
    "        \n",
    "        self.gradient[self.inputs[0]] = np.dot(grad_cost, weight.T)\n",
    "        self.gradient[self.inputs[1]] = np.dot(x.T, grad_cost)\n",
    "        self.gradient[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmod(Node):\n",
    "    def __init__(self, nodes):\n",
    "        Node.__init__(self, [nodes])\n",
    "    \n",
    "    def _sigmod(self, x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "    \n",
    "    def forward(self):\n",
    "        self.value = self._sigmod(self.inputs[0].value)\n",
    "        \n",
    "        return self.value\n",
    "        \n",
    "    def backward(self):\n",
    "        x = self.inputs[0].value\n",
    "        grad_cost = self.outputs[0].gradient[self]\n",
    "        #print(\"sigmod grad_cose {}\".format(grad_cost))\n",
    "        \n",
    "        #print(self._sigmod(x))\n",
    "        \n",
    "        self.gradient[self.inputs[0]] = grad_cost * self._sigmod(x) * (1 - self._sigmod(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Node):\n",
    "    def __init__(self, y, y_hat):\n",
    "        Node.__init__(self, [y, y_hat])\n",
    "        \n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        y_hat = self.inputs[1].value.reshape(-1, 1)\n",
    "        self.diff = y - y_hat\n",
    "        \n",
    "        self.value = np.mean(self.diff * self.diff)\n",
    "        \n",
    "        return self.value\n",
    "    \n",
    "    def backward(self):\n",
    "        m = self.diff.shape[0]\n",
    "        self.gradient[self.inputs[0]] = 2 / m * self.diff\n",
    "        self.gradient[self.inputs[1]] = -2 / m * self.diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = Input(), Input()\n",
    "w1, b1 = Input(), Input()\n",
    "w2, b2 = Input(), Input() \n",
    "\n",
    "l1 = Linear(x, w1, b1)\n",
    "s1 = Sigmod(l1)\n",
    "l2 = Linear(s1, w2, b2)\n",
    "\n",
    "mse = MSE(y, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data['data']\n",
    "train_y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = preprocessing.scale(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.value = train_x\n",
    "y.value = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.value = np.random.randn(13,10)\n",
    "b1.value = np.zeros(10)\n",
    "w2.value = np.random.randn(10,1)\n",
    "b2.value = np.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list = [x, w1, b1, w2, b2, l1, s1, l2, mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(graph, learn_rate):\n",
    "    loss = 1\n",
    "    \n",
    "    for i in range(5000):\n",
    "        for node in graph:\n",
    "            loss = node.forward()\n",
    "\n",
    "        for node in reversed(graph):\n",
    "            node.backward()\n",
    "        \n",
    "        graph[1].value -= learn_rate * graph[1].gradient[graph[1]]\n",
    "        graph[2].value -= learn_rate * graph[2].gradient[graph[2]]\n",
    "        graph[3].value -= learn_rate * graph[3].gradient[graph[3]]\n",
    "        graph[4].value -= learn_rate * graph[4].gradient[graph[4]]\n",
    "    \n",
    "        if i % 100 == 0:\n",
    "            print(\"loss is {}\".format(loss))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 571.9800381586145\n",
      "loss is 28.920231637154146\n",
      "loss is 22.641604772264063\n",
      "loss is 19.17678455508939\n",
      "loss is 15.87765334160036\n",
      "loss is 13.360110457103682\n",
      "loss is 11.78977485719423\n",
      "loss is 10.833928899730477\n",
      "loss is 10.230108820176618\n",
      "loss is 9.805312325416917\n",
      "loss is 9.47749790456153\n",
      "loss is 9.208704952586242\n",
      "loss is 8.979483782962108\n",
      "loss is 8.778959449850392\n",
      "loss is 8.600365525481104\n",
      "loss is 8.438982457374289\n",
      "loss is 8.291522376726967\n",
      "loss is 8.15602308856178\n",
      "loss is 8.031551348931384\n",
      "loss is 7.917629686319493\n",
      "loss is 7.8136634651185055\n",
      "loss is 7.718675936759738\n",
      "loss is 7.631402023190411\n",
      "loss is 7.550522285483147\n",
      "loss is 7.4748479709618\n",
      "loss is 7.403414195063489\n",
      "loss is 7.335502410412701\n",
      "loss is 7.270610946766635\n",
      "loss is 7.208383599077038\n",
      "loss is 7.148521447798603\n",
      "loss is 7.090722187115461\n",
      "loss is 7.034671050126436\n",
      "loss is 6.980066737109125\n",
      "loss is 6.9266541488806945\n",
      "loss is 6.874249266357528\n",
      "loss is 6.822752621026139\n",
      "loss is 6.772150457128175\n",
      "loss is 6.722503252681803\n",
      "loss is 6.6739233104684335\n",
      "loss is 6.626546071611657\n",
      "loss is 6.580501760439995\n",
      "loss is 6.53589355137112\n",
      "loss is 6.492785649653848\n",
      "loss is 6.451200999209204\n",
      "loss is 6.411125707803726\n",
      "loss is 6.372516616286829\n",
      "loss is 6.335309257638544\n",
      "loss is 6.299424728765361\n",
      "loss is 6.264775016704959\n",
      "loss is 6.231266881235791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.19912436253739"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(graph_list, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
