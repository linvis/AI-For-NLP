{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.value = None\n",
    "        self.outputs = []\n",
    "        \n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "        \n",
    "        self.gradient = {}\n",
    "        \n",
    "    def forward(self):\n",
    "        raise NotImplemented\n",
    "        \n",
    "    def backward(self):\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        Node.__init__(self)\n",
    "        \n",
    "    def forward(self):\n",
    "        return self.value\n",
    "        \n",
    "    def backward(self):\n",
    "        grad_cost = self.outputs[0].gradient[self]\n",
    "        self.gradient[self] = grad_cost.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Node):\n",
    "    def __init__(self, nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "        \n",
    "    def forward(self):\n",
    "        self.values = sum([n.value for n in self.inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weight, bias):\n",
    "        Node.__init__(self, [nodes, weight, bias])\n",
    "        \n",
    "    def forward(self):\n",
    "        x = self.inputs[0].value\n",
    "        weight = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "        \n",
    "        #weight = weight.reshape(-1, 1)\n",
    "        self.value = np.dot(x, weight) + bias\n",
    "        \n",
    "        return self.value\n",
    "        \n",
    "    def backward(self):\n",
    "        grad_cost = self.outputs[0].gradient[self]\n",
    "        #print(\"linear {}\".format(grad_cost.shape))\n",
    "        \n",
    "        x = self.inputs[0].value\n",
    "        weight = self.inputs[1].value\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #print(weight.shape)\n",
    "        #print(grad_cost.shape)\n",
    "        #grad_cost = grad_cost.reshape(grad_cost.shape[0], -1)\n",
    "        #weight = weight.reshape(weight.shape[0], -1)\n",
    "        \n",
    "        self.gradient[self.inputs[0]] = np.dot(grad_cost, weight.T)\n",
    "        self.gradient[self.inputs[1]] = np.dot(x.T, grad_cost)\n",
    "        self.gradient[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmod(Node):\n",
    "    def __init__(self, nodes):\n",
    "        Node.__init__(self, [nodes])\n",
    "    \n",
    "    def _sigmod(self, x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "    \n",
    "    def forward(self):\n",
    "        self.value = self._sigmod(self.inputs[0].value)\n",
    "        \n",
    "        return self.value\n",
    "        \n",
    "    def backward(self):\n",
    "        x = self.inputs[0].value\n",
    "        grad_cost = self.outputs[0].gradient[self]\n",
    "        #print(\"sigmod grad_cose {}\".format(grad_cost))\n",
    "        \n",
    "        #print(self._sigmod(x))\n",
    "        \n",
    "        self.gradient[self.inputs[0]] = grad_cost * self._sigmod(x) * (1 - self._sigmod(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Node):\n",
    "    def __init__(self, y, y_hat):\n",
    "        Node.__init__(self, [y, y_hat])\n",
    "        \n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        y_hat = self.inputs[1].value.reshape(-1, 1)\n",
    "        self.diff = y - y_hat\n",
    "        \n",
    "        self.value = np.mean(self.diff * self.diff)\n",
    "        \n",
    "        return self.value\n",
    "    \n",
    "    def backward(self):\n",
    "        m = self.diff.shape[0]\n",
    "        self.gradient[self.inputs[0]] = 2 / m * self.diff\n",
    "        self.gradient[self.inputs[1]] = -2 / m * self.diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = Input(), Input()\n",
    "w1, b1 = Input(), Input()\n",
    "w2, b2 = Input(), Input() \n",
    "\n",
    "l1 = Linear(x, w1, b1)\n",
    "s1 = Sigmod(l1)\n",
    "l2 = Linear(s1, w2, b2)\n",
    "\n",
    "mse = MSE(y, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1515,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data['data']\n",
    "train_y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1518,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = preprocessing.scale(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1519,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.value = train_x\n",
    "y.value = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1520,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.value = np.random.randn(13,10)\n",
    "b1.value = np.zeros(10)\n",
    "w2.value = np.random.randn(10,1)\n",
    "b2.value = np.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1521,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list = [x, w1, b1, w2, b2, l1, s1, l2, mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(graph, learn_rate):\n",
    "    loss = 1\n",
    "    \n",
    "    for i in range(5000):\n",
    "        for node in graph:\n",
    "            loss = node.forward()\n",
    "\n",
    "        \n",
    "\n",
    "        for node in reversed(graph):\n",
    "            node.backward()\n",
    "        \n",
    "        graph[1].value -= learn_rate * graph[1].gradient[graph[1]]\n",
    "        graph[2].value -= learn_rate * graph[2].gradient[graph[2]]\n",
    "        graph[3].value -= learn_rate * graph[3].gradient[graph[3]]\n",
    "        graph[4].value -= learn_rate * graph[4].gradient[graph[4]]\n",
    "    \n",
    "        if i % 100 == 0:\n",
    "            print(\"loss is {}\".format(loss))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 5.418679462076831\n",
      "loss is 5.392494438988442\n",
      "loss is 5.366717397618454\n",
      "loss is 5.341413477428093\n",
      "loss is 5.316638508772757\n",
      "loss is 5.292433261823772\n",
      "loss is 5.268821122558174\n",
      "loss is 5.245808697053098\n",
      "loss is 5.223388304024107\n",
      "loss is 5.201541288090174\n",
      "loss is 5.180241356281748\n",
      "loss is 5.159457478962694\n",
      "loss is 5.1391561663595065\n",
      "loss is 5.11930309336778\n",
      "loss is 5.099864118120434\n",
      "loss is 5.08080576639415\n",
      "loss is 5.062095278470086\n",
      "loss is 5.0437003773309526\n",
      "loss is 5.025589052556079\n",
      "loss is 5.007729885327553\n",
      "loss is 4.990093721365196\n",
      "loss is 4.9726575569258635\n",
      "loss is 4.955410638140654\n",
      "loss is 4.938360306092909\n",
      "loss is 4.921532520723938\n",
      "loss is 4.904964040272249\n",
      "loss is 4.888690945010128\n",
      "loss is 4.872742001120388\n",
      "loss is 4.857139231232892\n",
      "loss is 4.841901213760457\n",
      "loss is 4.827044705437071\n",
      "loss is 4.812583647870625\n",
      "loss is 4.7985268885489925\n",
      "loss is 4.784876310850413\n",
      "loss is 4.7716263564612955\n",
      "loss is 4.758764969275862\n",
      "loss is 4.746275374538638\n",
      "loss is 4.734138007440245\n",
      "loss is 4.722332136807466\n",
      "loss is 4.71083701934655\n",
      "loss is 4.69963261392009\n",
      "loss is 4.688699964023996\n",
      "loss is 4.678021361578054\n",
      "loss is 4.667580380135905\n",
      "loss is 4.6573618365514555\n",
      "loss is 4.647351717102882\n",
      "loss is 4.637537088637209\n",
      "loss is 4.627906005894088\n",
      "loss is 4.618447420761802\n",
      "loss is 4.609151096214136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.600098235170938"
      ]
     },
     "execution_count": 1527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(graph_list, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
